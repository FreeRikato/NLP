{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorials:\n",
    "1. [ Natural Language Processing (NLP) Tutorial with Python & NLTK](https://youtu.be/X2vAabgKiuM)\n",
    "2. [Spacy Introduction for NLP](https://www.youtube.com/watch?v=pLJm0WSIVDk&list=PLc2rvfiptPSSS-iwKS_lxI3MZr8Mbi4Zu)\n",
    "3. [TextBlob Library In Python For Natural Language Processing](https://www.youtube.com/watch?v=DedS74YKhs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import string\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rikato/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/rikato/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/rikato/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text for demonstration\n",
    "sample_text = \"\"\"\n",
    "Hello! This is a sample text for our NLP experiment. It contains punctuation, numbers (like 123), and special symbols (@#$).\n",
    "We'll perform various operations on this text. Some email addresses: john.doe@example.com, jane_smith@company.org.\n",
    "This text also includes some common words and potential spelling errors, such as 'langauge' instead of 'language'.\n",
    "NLP is gr8 for txt analysis. ROFL!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "\n",
      "Hello! This is a sample text for our NLP experiment. It contains punctuation, numbers (like 123), and special symbols (@#$).\n",
      "We'll perform various operations on this text. Some email addresses: john.doe@example.com, jane_smith@company.org.\n",
      "This text also includes some common words and potential spelling errors, such as 'langauge' instead of 'language'.\n",
      "NLP is gr8 for txt analysis. ROFL!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Text:\")\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a. Remove punctuations, special symbols, numbers using regular expression\n",
    "def remove_punct_symbols_numbers(text):\n",
    "    return re.sub(r'[^\\w\\s]|\\d', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1a. Text after removing punctuations, special symbols, and numbers:\n",
      "\n",
      "Hello This is a sample text for our NLP experiment It contains punctuation numbers like  and special symbols \n",
      "Well perform various operations on this text Some email addresses johndoeexamplecom jane_smithcompanyorg\n",
      "This text also includes some common words and potential spelling errors such as langauge instead of language\n",
      "NLP is gr for txt analysis ROFL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1a. Text after removing punctuations, special symbols, and numbers:\")\n",
    "cleaned_text = remove_punct_symbols_numbers(sample_text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b. Tokenize the text into sentences\n",
    "def tokenize_sentences(text):\n",
    "    return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1b. Tokenized sentences:\n",
      "Sentence 1: \n",
      "Hello!\n",
      "Sentence 2: This is a sample text for our NLP experiment.\n",
      "Sentence 3: It contains punctuation, numbers (like 123), and special symbols (@#$).\n",
      "Sentence 4: We'll perform various operations on this text.\n",
      "Sentence 5: Some email addresses: john.doe@example.com, jane_smith@company.org.\n",
      "Sentence 6: This text also includes some common words and potential spelling errors, such as 'langauge' instead of 'language'.\n",
      "Sentence 7: NLP is gr8 for txt analysis.\n",
      "Sentence 8: ROFL!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1b. Tokenized sentences:\")\n",
    "sentences = tokenize_sentences(sample_text)\n",
    "for i, sentence in enumerate(sentences, 1):\n",
    "    print(f\"Sentence {i}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1c. Add Custom Stopwords and List Removed Stopwords\n",
    "def remove_stopwords(text, custom_stopwords=[]):\n",
    "    stop_words = set(stopwords.words('english') + custom_stopwords)\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    removed_stopwords = [word for word in words if word.lower() in stop_words]\n",
    "    return ' '.join(filtered_words), removed_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1c. Text after removing stopwords (including custom stopwords):\n",
      "Hello text NLP experiment punctuation numbers like special symbols Well perform various operations text email addresses johndoeexamplecom jane_smithcompanyorg text also includes common words potential spelling errors langauge instead language NLP gr txt analysis ROFL\n",
      "Removed stopwords: ['This', 'is', 'a', 'sample', 'for', 'our', 'It', 'contains', 'and', 'on', 'this', 'Some', 'This', 'some', 'and', 'such', 'as', 'of', 'is', 'for']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1c. Text after removing stopwords (including custom stopwords):\")\n",
    "custom_stopwords = ['sample', 'contains']\n",
    "text_without_stopwords, removed_stopwords = remove_stopwords(cleaned_text, custom_stopwords)\n",
    "print(text_without_stopwords)\n",
    "print(\"Removed stopwords:\", removed_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1d. Perform stemming and lemmatization\n",
    "def stem_and_lemmatize(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(text)\n",
    "    stemmed = [stemmer.stem(word) for word in words]\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(stemmed), ' '.join(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1d. Stemmed and Lemmatized text:\n",
      "Stemmed: hello thi is a sampl text for our nlp experi it contain punctuat number like and special symbol well perform variou oper on thi text some email address johndoeexamplecom jane_smithcompanyorg thi text also includ some common word and potenti spell error such as langaug instead of languag nlp is gr for txt analysi rofl\n",
      "Lemmatized: Hello This is a sample text for our NLP experiment It contains punctuation number like and special symbol Well perform various operation on this text Some email address johndoeexamplecom jane_smithcompanyorg This text also includes some common word and potential spelling error such a langauge instead of language NLP is gr for txt analysis ROFL\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1d. Stemmed and Lemmatized text:\")\n",
    "stemmed, lemmatized = stem_and_lemmatize(cleaned_text)\n",
    "print(\"Stemmed:\", stemmed)\n",
    "print(\"Lemmatized:\", lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1e. Extract usernames from email addresses\n",
    "def extract_usernames(text):\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    emails = re.findall(email_pattern, text)\n",
    "    usernames = [email.split('@')[0] for email in emails]\n",
    "    return usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1e. Extracted usernames from email addresses:\n",
      "['john.doe', 'jane_smith']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1e. Extracted usernames from email addresses:\")\n",
    "usernames = extract_usernames(sample_text)\n",
    "print(usernames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1f. Find the most common words\n",
    "def find_common_words(text, n=10):\n",
    "    words = word_tokenize(text.lower())\n",
    "    word_freq = Counter(words)\n",
    "    return word_freq.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1f. Most common words:\n",
      "this: 3\n",
      "text: 3\n",
      "is: 2\n",
      "for: 2\n",
      "nlp: 2\n",
      "and: 2\n",
      "some: 2\n",
      "hello: 1\n",
      "a: 1\n",
      "sample: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1f. Most common words:\")\n",
    "common_words = find_common_words(cleaned_text)\n",
    "for word, count in common_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1g. Correct spelling errors\n",
    "def correct_spelling(text):\n",
    "    return str(TextBlob(text).correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1g. Text after spelling correction:\n",
      "\n",
      "Hello! His is a sample text for our NLP experiment. It contains punctuation, numbers (like 123), and special symbols (@#$).\n",
      "He'll perform various operations on this text. Some email addresses: john.doe@example.com, jane_smith@company.org.\n",
      "His text also includes some common words and potential spelling errors, such as 'language' instead of 'language'.\n",
      "NLP is grm for txt analysis. ROFL!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1g. Text after spelling correction:\")\n",
    "corrected_text = correct_spelling(sample_text)\n",
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a. Replace social media slangs\n",
    "def replace_slangs(text, slang_dict):\n",
    "    words = word_tokenize(text)\n",
    "    replaced_words = [slang_dict.get(word.lower(), word) for word in words]\n",
    "    return ' '.join(replaced_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2a. Text after replacing social media slangs:\n",
      "Hello ! This is a sample text for our NLP experiment . It contains punctuation , numbers ( like 123 ) , and special symbols ( @ # $ ) . We 'll perform various operations on this text . Some email addresses : john.doe @ example.com , jane_smith @ company.org . This text also includes some common words and potential spelling errors , such as 'langauge ' instead of 'language ' . NLP is great for text analysis . rolling on the floor laughing !\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2a. Text after replacing social media slangs:\")\n",
    "slang_dict = {'gr8': 'great', 'txt': 'text', 'rofl': 'rolling on the floor laughing'}\n",
    "text_without_slangs = replace_slangs(sample_text, slang_dict)\n",
    "print(text_without_slangs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b. Apply stemming or lemmatization only if the word doesn't have meaning\n",
    "def smart_stem_lemmatize(text):\n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(text)\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        if not d.check(word):\n",
    "            lemma = lemmatizer.lemmatize(word)\n",
    "            if d.check(lemma):\n",
    "                processed_words.append(lemma)\n",
    "            else:\n",
    "                processed_words.append(word)\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "    return ' '.join(processed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2b. Text after smart stemming/lemmatization:\n",
      "Hello This is a sample text for our NLP experiment It contains punctuation numbers like and special symbols Well perform various operations on this text Some email addresses johndoeexamplecom jane_smithcompanyorg This text also includes some common words and potential spelling errors such as langauge instead of language NLP is gr for txt analysis ROFL\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2b. Text after smart stemming/lemmatization:\")\n",
    "smart_processed_text = smart_stem_lemmatize(cleaned_text)\n",
    "print(smart_processed_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NLPvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
